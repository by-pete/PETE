{
  // =============================================
  // OPENCLAW.JSON — PRODUCTION CONFIG
  // Robert Clausing / n0v8v LLC
  // Optimized for: token cost control, vectorized memory,
  // reference-file-based context (small input, rich output)
  // =============================================

  // GATEWAY — Security first
  "gateway": {
    "bind": "loopback",
    "port": 18789,
    "maxConcurrent": 6
  },

  // =============================================
  // MODEL TIERING — Pay for OUTPUT not INPUT
  // Strategy: Cheap models for routine, expensive for output-heavy work
  // =============================================
  "agents": {
    "defaults": {

      // PRIMARY: Sonnet for 80% of daily work ($3/$15 per 1M)
      // Opus only when you explicitly need it
      "model": {
        "primary": "anthropic/claude-sonnet-4-5",
        "fallbacks": [
          "openai/gpt-5-mini",
          "openrouter/google/gemini-3-flash-preview"
        ]
      },

      "models": {
        "anthropic/claude-sonnet-4-5": { "alias": "sonnet" },
        "anthropic/claude-opus-4-6": { "alias": "opus" },
        "anthropic/claude-haiku-4-5": { "alias": "haiku" },
        "openai/gpt-5-mini": { "alias": "mini" },
        "openrouter/google/gemini-3-flash-preview": { "alias": "flash" }
      },

      // =============================================
      // MEMORY — Vectorized hybrid search with cheap embeddings
      // This is the core: tiny token send, rich retrieval
      // =============================================
      "memorySearch": {
        "enabled": true,
        "sources": ["memory", "sessions"],
        "experimental": {
          "sessionMemory": true
        },
        // CHEAP embeddings — $0.02/1M tokens vs $0.13 for ada-002
        "provider": "openai",
        "model": "text-embedding-3-small",
        "sync": {
          "onSessionStart": true,
          "watch": true
        },
        "query": {
          "maxResults": 8,
          "hybrid": {
            "enabled": true,
            "vectorWeight": 0.7,
            "textWeight": 0.3,
            "candidateMultiplier": 4,
            // Reduce duplicate daily notes from cluttering results
            "mmr": {
              "enabled": true,
              "lambda": 0.7
            },
            // Boost recent context, decay old noise
            "temporalDecay": {
              "enabled": true,
              "halfLifeDays": 45
            }
          }
        }
      },

      // =============================================
      // CONTEXT PRUNING — Kill the #1 cost driver
      // Cache-TTL mode: prune old context after cache expires
      // This prevents the "200K token context on a simple question" problem
      // =============================================
      "contextPruning": {
        "mode": "cache-ttl",
        "ttl": "4h",
        "keepLastAssistants": 3
      },

      // =============================================
      // COMPACTION — Auto-flush sessions to memory files
      // Instead of losing context, distill it to searchable memory
      // =============================================
      "compaction": {
        "mode": "default",
        "memoryFlush": {
          "enabled": true,
          "softThresholdTokens": 35000,
          "prompt": "Distill this session to memory/YYYY-MM-DD.md. Extract: decisions made, state changes, action items, blockers, client/project updates, lessons learned. Tag each item [BUNTING] or [N0V8V] or [PERSONAL] or [SYSTEM]. If nothing worth storing: NO_FLUSH",
          "systemPrompt": "Extract only what is worth remembering. No fluff. No conversation replay. Structured, searchable, tagged."
        }
      },

      // =============================================
      // HEARTBEAT — Isolated to prevent context bleed
      // KEY INSIGHT: Native heartbeat carries full session context = expensive
      // Isolated heartbeat is cheap and bounded
      // =============================================
      "heartbeat": {
        "every": "30m",
        "target": "last",
        "activeHours": {
          "start": "06:00",
          "end": "22:00"
        }
        // Enable reasoning delivery for transparency during debugging:
        // "includeReasoning": true
      },

      // Reduce screenshot token waste
      "imageMaxDimensionPx": 1024
    },

    // =============================================
    // NAMED AGENTS — Specialized roles with appropriate models
    // Cheap models for monitoring, expensive for strategic work
    // =============================================
    "named": {
      // Heartbeat/monitoring agent — CHEAP model, isolated context
      "monitor": {
        "model": {
          "primary": "anthropic/claude-haiku-4-5",
          "fallbacks": ["openrouter/google/gemini-3-flash-preview"]
        }
      },

      // Strategic/consulting work — Full power when needed
      "strategist": {
        "model": {
          "primary": "anthropic/claude-opus-4-6",
          "fallbacks": ["anthropic/claude-sonnet-4-5"]
        }
      },

      // Research agent — Good reasoning, moderate cost
      "researcher": {
        "model": {
          "primary": "anthropic/claude-sonnet-4-5",
          "fallbacks": ["openai/gpt-5-mini"]
        }
      }
    }
  },

  // =============================================
  // CHANNELS — Connect messaging surfaces
  // =============================================
  "channels": {
    "discord": {
      "enabled": true,
      "dmPolicy": "pairing",
      "token": "<YOUR_DISCORD_BOT_TOKEN>",
      "groupPolicy": "allowlist",
      "streamMode": "partial"
    },
    "telegram": {
      "enabled": false,
      "dmPolicy": "pairing",
      "botToken": "<YOUR_TELEGRAM_BOT_TOKEN>"
    }
  }
}
